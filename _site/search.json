[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Papers",
    "section": "",
    "text": "I have read.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\n2023-08-16\n\n\nLoRA: Low Ranked Adaption of Large-Language Models\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "papers/001_LoRA.html",
    "href": "papers/001_LoRA.html",
    "title": "LoRA: Low Ranked Adaption of Large-Language Models",
    "section": "",
    "text": "ðŸ“ƒ https://arxiv.org/abs/2106.09685\nAuthors"
  },
  {
    "objectID": "papers/001_LoRA.html#results",
    "href": "papers/001_LoRA.html#results",
    "title": "LoRA: Low Ranked Adaption of Large-Language Models",
    "section": "Results",
    "text": "Results\n\nInference Latency\n\n\n\nBenchmark scores\n\n\n\n\nScaling up: GPT-3 175b\n\n\n\nWhich weights should we pick?"
  }
]